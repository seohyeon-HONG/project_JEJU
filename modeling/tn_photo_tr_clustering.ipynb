{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T06:58:22.226030Z",
     "start_time": "2025-02-01T06:58:10.864268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import hdbscan\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image"
   ],
   "id": "e907c09fdfcfdc38",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T06:58:26.978485Z",
     "start_time": "2025-02-01T06:58:26.951561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# `umap-learn` 패키지가 제대로 로드되지 않는 경우를 대비한 경로 추가\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\user\\anaconda3\\envs\\my_new_env\\lib\\site-packages\")"
   ],
   "id": "d744540fa5e74bd4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-01T06:59:28.497415Z",
     "start_time": "2025-02-01T06:59:28.476640Z"
    }
   },
   "source": [
    "folder_path =r\"E:\\AI_HUB\\data\\Training\\raw_data\\TS_photo\"\n",
    "save_path = r\"E:\\AI_HUB\\data\\Training\\raw_data\\TS_photo\\features\"\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T07:01:13.994754Z",
     "start_time": "2025-02-01T07:01:13.982962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 파일 경로 생성\n",
    "features_path = os.path.join(save_path, \"clip_features.npy\")\n",
    "image_names_path = os.path.join(save_path, \"clip_image_names.npy\")"
   ],
   "id": "8288ed71fd8eae88",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T06:18:49.310332Z",
     "start_time": "2025-02-01T06:18:49.298368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ✅ 이미지 로드 함수\n",
    "def load_images(folder_path, limit=3000):\n",
    "    image_files = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_files.append(os.path.join(root, file))\n",
    "    return random.sample(image_files, limit) if len(image_files) > limit else image_files"
   ],
   "id": "a427f76a5fd774ef",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T06:18:58.507743Z",
     "start_time": "2025-02-01T06:18:49.352245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ✅ CLIP 모델 로드\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ],
   "id": "e790bf0a293a50aa",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T06:18:58.553312Z",
     "start_time": "2025-02-01T06:18:58.541877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ✅ 이미지 특징 벡터 추출 함수\n",
    "def extract_features_clip(image_path):\n",
    "    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        features = model.encode_image(image)\n",
    "    return features.cpu().numpy().flatten()"
   ],
   "id": "ef8cc0d9f4a7cbcb",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-02-01T06:18:58.593148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # ✅ 3000장 랜덤 이미지 선택 및 특징 추출\n",
    "# image_files = load_images(folder_path, limit=3000)\n",
    "# features = np.array([extract_features_clip(img) for img in image_files])\n",
    "# image_names = [os.path.basename(img) for img in image_files]"
   ],
   "id": "94e2daa8fe75cd4c",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# ✅ 3000장 랜덤 이미지 선택 및 특징 추출\u001B[39;00m\n\u001B[0;32m      2\u001B[0m image_files \u001B[38;5;241m=\u001B[39m load_images(folder_path, limit\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3000\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m features \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([extract_features_clip(img) \u001B[38;5;28;01mfor\u001B[39;00m img \u001B[38;5;129;01min\u001B[39;00m image_files])\n\u001B[0;32m      4\u001B[0m image_names \u001B[38;5;241m=\u001B[39m [os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(img) \u001B[38;5;28;01mfor\u001B[39;00m img \u001B[38;5;129;01min\u001B[39;00m image_files]\n",
      "Cell \u001B[1;32mIn[29], line 3\u001B[0m, in \u001B[0;36mextract_features_clip\u001B[1;34m(image_path)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mextract_features_clip\u001B[39m(image_path):\n\u001B[1;32m----> 3\u001B[0m     image \u001B[38;5;241m=\u001B[39m preprocess(Image\u001B[38;5;241m.\u001B[39mopen(image_path))\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m      5\u001B[0m         features \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mencode_image(image)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m---> 95\u001B[0m         img \u001B[38;5;241m=\u001B[39m t(img)\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:386\u001B[0m, in \u001B[0;36mCenterCrop.forward\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m    378\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m    379\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    381\u001B[0m \u001B[38;5;124;03m        img (PIL Image or Tensor): Image to be cropped.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    384\u001B[0m \u001B[38;5;124;03m        PIL Image or Tensor: Cropped image.\u001B[39;00m\n\u001B[0;32m    385\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 386\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mcenter_crop(img, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msize)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\functional.py:594\u001B[0m, in \u001B[0;36mcenter_crop\u001B[1;34m(img, output_size)\u001B[0m\n\u001B[0;32m    592\u001B[0m crop_top \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mround\u001B[39m((image_height \u001B[38;5;241m-\u001B[39m crop_height) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2.0\u001B[39m))\n\u001B[0;32m    593\u001B[0m crop_left \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mround\u001B[39m((image_width \u001B[38;5;241m-\u001B[39m crop_width) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2.0\u001B[39m))\n\u001B[1;32m--> 594\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m crop(img, crop_top, crop_left, crop_height, crop_width)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\functional.py:551\u001B[0m, in \u001B[0;36mcrop\u001B[1;34m(img, top, left, height, width)\u001B[0m\n\u001B[0;32m    549\u001B[0m     _log_api_usage_once(crop)\n\u001B[0;32m    550\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(img, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m--> 551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F_pil\u001B[38;5;241m.\u001B[39mcrop(img, top, left, height, width)\n\u001B[0;32m    553\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m F_t\u001B[38;5;241m.\u001B[39mcrop(img, top, left, height, width)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:235\u001B[0m, in \u001B[0;36mcrop\u001B[1;34m(img, top, left, height, width)\u001B[0m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_pil_image(img):\n\u001B[0;32m    233\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg should be PIL Image. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(img)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 235\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m img\u001B[38;5;241m.\u001B[39mcrop((left, top, left \u001B[38;5;241m+\u001B[39m width, top \u001B[38;5;241m+\u001B[39m height))\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1243\u001B[0m, in \u001B[0;36mImage.crop\u001B[1;34m(self, box)\u001B[0m\n\u001B[0;32m   1240\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m   1242\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mload()\n\u001B[1;32m-> 1243\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_new(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_crop(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mim, box))\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1263\u001B[0m, in \u001B[0;36mImage._crop\u001B[1;34m(self, im, box)\u001B[0m\n\u001B[0;32m   1259\u001B[0m absolute_values \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mabs\u001B[39m(x1 \u001B[38;5;241m-\u001B[39m x0), \u001B[38;5;28mabs\u001B[39m(y1 \u001B[38;5;241m-\u001B[39m y0))\n\u001B[0;32m   1261\u001B[0m _decompression_bomb_check(absolute_values)\n\u001B[1;32m-> 1263\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m im\u001B[38;5;241m.\u001B[39mcrop((x0, y0, x1, y1))\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T06:39:45.426805Z",
     "start_time": "2025-02-01T06:39:44.986845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # ✅ 특징 벡터 저장\n",
    "# np.save(os.path.join(save_path, \"clip_features.npy\"), features)\n",
    "# np.save(os.path.join(save_path, \"clip_image_names.npy\"), np.array(image_names))"
   ],
   "id": "aab6e0c6ec8c3702",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T07:02:26.413907Z",
     "start_time": "2025-02-01T07:02:26.399992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 저장된 NumPy 배열 불러오기\n",
    "features = np.load(features_path)\n",
    "image_names = np.load(image_names_path)"
   ],
   "id": "32badcafced31597",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T06:59:28.451382Z",
     "start_time": "2025-02-01T06:58:32.332213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import umap\n",
    "print(umap.__file__)"
   ],
   "id": "48a73b6b9ecf0abb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\umap\\__init__.py\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T06:49:53.679018Z",
     "start_time": "2025-02-01T06:49:53.673218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "umap = importlib.import_module(\"umap\")\n",
    "print(umap)"
   ],
   "id": "986cc001803a5a8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'umap' (namespace) from ['C:\\\\Users\\\\user\\\\anaconda3\\\\Lib\\\\site-packages\\\\umap']>\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T07:08:53.150124Z",
     "start_time": "2025-02-01T07:08:21.746057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from umap import UMAP  # 올바른 임포트\n",
    "\n",
    "# UMAP 차원 축소 (2D) - n_neighbors 줄이기\n",
    "umap_2d = UMAP(\n",
    "    n_components=2,\n",
    "    n_neighbors=20,\n",
    "    min_dist=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "features_2d = umap_2d.fit_transform(features)"
   ],
   "id": "f06f720efb122e00",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T07:09:54.470562Z",
     "start_time": "2025-02-01T07:09:54.403200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# HDBSCAN 클러스터링 적용 - min_cluster_size 조정\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=10, \n",
    "                            min_samples=3, \n",
    "                            metric=\"manhattan\")\n",
    "labels = clusterer.fit_predict(features_2d)"
   ],
   "id": "ca0bf6f7b51bcf59",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T07:09:56.499564Z",
     "start_time": "2025-02-01T07:09:56.477723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 클러스터링 결과 저장\n",
    "np.save(os.path.join(save_path, \"cluster_labels.npy\"), labels)\n",
    "\n",
    "# 클러스터 개수 출력\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print(f\"📌 생성된 클러스터 개수: {n_clusters}\")"
   ],
   "id": "fdaaf7dc64dd94c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 생성된 클러스터 개수: 2\n"
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
