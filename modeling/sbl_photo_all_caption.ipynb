{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T07:21:32.298049Z",
     "start_time": "2025-01-25T07:21:11.921471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import clip\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# JSON 데이터 로드\n",
    "json_file_path = r\"E:\\AI_HUB\\data\\Sublabel\\SbL\\extracted_data_all_caption.json\"\n",
    "with open(json_file_path, 'r', encoding='utf-8-sig') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# 최대 길이 설정 (CLIP 모델의 컨텍스트 제한)\n",
    "MAX_CONTEXT_LENGTH = 77\n",
    "\n",
    "def truncate_text(text, max_length=77):\n",
    "    \"\"\"\n",
    "    입력 텍스트를 공백 단위로 나눠서 최대 길이에 맞게 자릅니다.\n",
    "    \"\"\"\n",
    "    tokens = text.split()  # 공백 기준으로 텍스트를 나눕니다.\n",
    "    if len(tokens) > max_length:\n",
    "        tokens = tokens[:max_length]  # 최대 길이에 맞게 자르기\n",
    "    return \" \".join(tokens)  # 다시 문자열로 변환\n",
    "\n",
    "# 이미지 데이터셋 클래스 정의\n",
    "class TourismDataset(Dataset):\n",
    "    def __init__(self, data, image_dir, preprocess):\n",
    "        self.data = data\n",
    "        self.image_dir = image_dir\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "        # 이미지와 텍스트 매칭 데이터 생성\n",
    "        self.samples = [\n",
    "            (\n",
    "                os.path.join(image_dir, entry[\"PHOTO_FILE_NM\"]),\n",
    "                truncate_text(entry[\"CAPTION\"])  # 공백 기준 자르기\n",
    "            )\n",
    "            for entry in data\n",
    "            if os.path.exists(os.path.join(image_dir, entry[\"PHOTO_FILE_NM\"]))\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, keywords = self.samples[idx]\n",
    "        image = self.preprocess(Image.open(image_path).convert(\"RGB\"))\n",
    "        return image, keywords\n",
    "\n",
    "# CLIP 모델과 Preprocessor 로드\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "image_directory = r\"E:\\AI_HUB\\data\\Sublabel\\SbL\\photo\"\n",
    "\n",
    "# 데이터셋 생성 및 DataLoader 정의\n",
    "dataset = TourismDataset(data, image_directory, preprocess)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# 학습 루프\n",
    "for batch_idx, (images, texts) in enumerate(tqdm(dataloader)):\n",
    "    try:\n",
    "        # 이미지를 GPU로 이동\n",
    "        images = images.to(device)\n",
    "\n",
    "        # 텍스트를 잘라주기 (공백 기준으로 토큰 제한)\n",
    "        texts = [truncate_text(text, max_length=77) for text in texts]\n",
    "\n",
    "        # CLIP의 토크나이저를 사용하여 텍스트를 토큰화\n",
    "        texts = clip.tokenize(texts).to(device)\n",
    "\n",
    "        # 이미지와 텍스트 특징 추출\n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(images)\n",
    "            text_features = model.encode_text(texts)\n",
    "\n",
    "        # 정규화\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # 유사도 계산\n",
    "        similarity = (image_features @ text_features.T).cpu().numpy()\n",
    "        print(f\"Batch {batch_idx + 1} 유사도 매트릭스:\\n\", similarity)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"에러 발생 (Batch {batch_idx + 1}): {e}\")\n",
    "        continue\n"
   ],
   "id": "58c6eda8929ca265",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/192 [00:06<20:04,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 유사도 매트릭스:\n",
      " [[0.17020105 0.17129105 0.17733842 0.17619379 0.18143858 0.18230945\n",
      "  0.18028206 0.17333719 0.17707315 0.18288758 0.18431638 0.17565092\n",
      "  0.18411355 0.18237752 0.18496178 0.17897412]\n",
      " [0.19158983 0.19149037 0.19304098 0.1968408  0.19221082 0.20151448\n",
      "  0.19716525 0.19107756 0.19363311 0.19929165 0.1856907  0.18759494\n",
      "  0.19773772 0.19662893 0.19990723 0.19608682]\n",
      " [0.18061806 0.1796092  0.18624139 0.19643551 0.18115    0.19708642\n",
      "  0.19342372 0.18472905 0.18983759 0.19279008 0.18099841 0.18430218\n",
      "  0.18915775 0.19314033 0.20664299 0.18859376]\n",
      " [0.19783255 0.19889504 0.19965322 0.20548797 0.19667627 0.21122345\n",
      "  0.20374973 0.20006439 0.19824201 0.2051678  0.20442162 0.19551131\n",
      "  0.20614426 0.20566987 0.2142874  0.20052731]\n",
      " [0.17653345 0.17833738 0.17884193 0.18619439 0.1743839  0.18645924\n",
      "  0.1821909  0.17875864 0.178839   0.18049374 0.17321876 0.17291574\n",
      "  0.17964497 0.1806088  0.19578326 0.1765399 ]\n",
      " [0.18650794 0.1839263  0.18774068 0.19899441 0.19012392 0.20166531\n",
      "  0.19265723 0.1910636  0.18825148 0.19971296 0.18709403 0.19118898\n",
      "  0.19696128 0.20321754 0.21020243 0.19377173]\n",
      " [0.1768178  0.18094933 0.1775982  0.18213704 0.1724768  0.18563543\n",
      "  0.18031819 0.17572981 0.17795281 0.17918004 0.1781261  0.17122018\n",
      "  0.17946813 0.18047373 0.1912797  0.17728429]\n",
      " [0.21118206 0.21649607 0.21137351 0.21481419 0.20560437 0.2165735\n",
      "  0.21121126 0.20863485 0.21123573 0.21191925 0.20493324 0.20123668\n",
      "  0.2151949  0.21472447 0.22457427 0.209585  ]\n",
      " [0.20931262 0.2137729  0.21020332 0.22422987 0.20753637 0.21985872\n",
      "  0.21582016 0.20914802 0.21343638 0.2180656  0.21229264 0.2082267\n",
      "  0.21311702 0.21946472 0.22866169 0.2150693 ]\n",
      " [0.21899304 0.22223501 0.22487566 0.23054029 0.21929325 0.2288253\n",
      "  0.2243931  0.21794511 0.217742   0.22630629 0.2221766  0.2173555\n",
      "  0.22587572 0.23076072 0.23942098 0.22886686]\n",
      " [0.18031025 0.18368104 0.18493064 0.18860148 0.18494195 0.18810761\n",
      "  0.18672185 0.18635315 0.1864789  0.18785068 0.1832609  0.17701015\n",
      "  0.18806234 0.18990347 0.19645211 0.18679947]\n",
      " [0.19478786 0.1947267  0.19175532 0.20182195 0.1854826  0.20388174\n",
      "  0.19607976 0.19087273 0.19665912 0.19953907 0.19965792 0.18844062\n",
      "  0.19487925 0.20098989 0.20815575 0.19747318]\n",
      " [0.22768535 0.23252726 0.22918807 0.23694149 0.22665176 0.23895177\n",
      "  0.23172075 0.2291155  0.2300878  0.23332867 0.23225398 0.22298954\n",
      "  0.23198658 0.23448248 0.24888942 0.227176  ]\n",
      " [0.17262    0.17026842 0.17965034 0.17808881 0.17505491 0.18287838\n",
      "  0.18055505 0.17696254 0.17949754 0.18243837 0.16934192 0.1796197\n",
      "  0.18403614 0.18373996 0.1842261  0.18335862]\n",
      " [0.19099905 0.19086584 0.19703218 0.20495322 0.19644849 0.20344591\n",
      "  0.1986137  0.19593838 0.19691968 0.2034662  0.19457278 0.19551523\n",
      "  0.20383486 0.20873228 0.2177493  0.20009618]\n",
      " [0.19478813 0.19460095 0.19885866 0.20415947 0.2013408  0.20968628\n",
      "  0.20287573 0.19565685 0.19682199 0.20409685 0.19293635 0.19879018\n",
      "  0.20326033 0.20376986 0.21199183 0.20054069]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/192 [00:12<19:25,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에러 발생 (Batch 2): Input 좌측에 건물들과 울타리와 돌들이 있고 아래쪽에 도로가 있고 우측에 울타리와 나무들이 있습니다 is too long for context length 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/192 [00:15<24:44,  7.82s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[47], line 62\u001B[0m\n\u001B[0;32m     59\u001B[0m dataloader \u001B[38;5;241m=\u001B[39m DataLoader(dataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     61\u001B[0m \u001B[38;5;66;03m# 학습 루프\u001B[39;00m\n\u001B[1;32m---> 62\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, (images, texts) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(tqdm(dataloader)):\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     64\u001B[0m         \u001B[38;5;66;03m# 이미지를 GPU로 이동\u001B[39;00m\n\u001B[0;32m     65\u001B[0m         images \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    707\u001B[0m ):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[1;32mIn[47], line 48\u001B[0m, in \u001B[0;36mTourismDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[0;32m     47\u001B[0m     image_path, keywords \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples[idx]\n\u001B[1;32m---> 48\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(Image\u001B[38;5;241m.\u001B[39mopen(image_path)\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m image, keywords\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:941\u001B[0m, in \u001B[0;36mImage.convert\u001B[1;34m(self, mode, matrix, dither, palette, colors)\u001B[0m\n\u001B[0;32m    889\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconvert\u001B[39m(\n\u001B[0;32m    890\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    891\u001B[0m     mode: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    895\u001B[0m     colors: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m256\u001B[39m,\n\u001B[0;32m    896\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Image:\n\u001B[0;32m    897\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    898\u001B[0m \u001B[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001B[39;00m\n\u001B[0;32m    899\u001B[0m \u001B[38;5;124;03m    method translates pixels through the palette.  If mode is\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    938\u001B[0m \u001B[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001B[39;00m\n\u001B[0;32m    939\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 941\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mload()\n\u001B[0;32m    943\u001B[0m     has_transparency \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransparency\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\n\u001B[0;32m    944\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m mode \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mP\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    945\u001B[0m         \u001B[38;5;66;03m# determine default mode\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\PIL\\ImageFile.py:291\u001B[0m, in \u001B[0;36mImageFile.load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    288\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(msg)\n\u001B[0;32m    290\u001B[0m b \u001B[38;5;241m=\u001B[39m b \u001B[38;5;241m+\u001B[39m s\n\u001B[1;32m--> 291\u001B[0m n, err_code \u001B[38;5;241m=\u001B[39m decoder\u001B[38;5;241m.\u001B[39mdecode(b)\n\u001B[0;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    293\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 47
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
